=========================================================
Epoch: 0
=========================================================
[34m[1mwandb[39m[22m: [33mWARNING[39m Symlinked 0 file into the W&B run directory, call wandb.save again to sync new files.
pretrain:   0%|                                                                                                                                    | 0/1079 [00:08<?, ?it/s]
Traceback (most recent call last):
  File "moco.py", line 149, in <module>
    Pretext(q_encoder, k_encoder, m, queue, n_queue, optimizer, n_epochs, criterion, pretext_loader, test_subjects, wb, device, SAVE_PATH, BATCH_SIZE)
  File "/home2/vivek.talwar/ssl-models/moco/train.py", line 188, in Pretext
    loss = criterion(anchor, positive, queue)
  File "/home2/vivek.talwar/miniconda3/envs/torch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home2/vivek.talwar/ssl-models/moco/loss.py", line 23, in forward
    l_neg = torch.einsum('nc,kc->nk', [anchor, queue])
  File "/home2/vivek.talwar/miniconda3/envs/torch/lib/python3.8/site-packages/torch/functional.py", line 325, in einsum
    return einsum(equation, *_operands)
  File "/home2/vivek.talwar/miniconda3/envs/torch/lib/python3.8/site-packages/torch/functional.py", line 327, in einsum
    return _VF.einsum(equation, operands)  # type: ignore[attr-defined]
RuntimeError: einsum(): operands do not broadcast with remapped shapes [original->remapped]: [128, 128]->[128, 1, 128] [4096, 256]->[1, 4096, 256]